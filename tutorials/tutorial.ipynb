{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show various snippets of code for varios tasks using the audio and video functionalities provided by the `pipepal` package. \n",
    "\n",
    "Please note that all file paths and configurations used here are placeholders and should be replaced with actual user-specific paths and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary classes from the pipepal package\n",
    "from pipepal.audio.tasks import ExampleTask, IOTask as AudioIOTask\n",
    "from pipepal.video.tasks import IOTask as VideoIOTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Audio Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Task\n",
    "# ------------\n",
    "# This section demonstrates the usage of the ExampleTask which is a basic template task.\n",
    "\n",
    "# Creating an instance of ExampleTask\n",
    "example_task = ExampleTask()\n",
    "\n",
    "# Running the example task with sample data and service configurations\n",
    "example_response = example_task.run({\n",
    "    \"data\": {\n",
    "        \"hello\": \"world\"\n",
    "    },\n",
    "    \"service\": {\n",
    "        \"service_name\": \"ExampleService\",\n",
    "        \"model_checkpoint\": \"model.ckpt\",\n",
    "        \"model_version\": \"1.0\",\n",
    "    }\n",
    "})\n",
    "\n",
    "# Output the response from the example task\n",
    "print(\"Example Task Response:\", example_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video IO Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video IO Task\n",
    "# -------------\n",
    "# This section illustrates how to extract audio tracks from video files using VideoIOTask.\n",
    "\n",
    "# Creating an instance of VideoIOTask\n",
    "video_io_task = VideoIOTask()\n",
    "\n",
    "# Extracting audio from video\n",
    "video_io_response = video_io_task.extract_audios_from_videos({\n",
    "    \"data\": {\n",
    "        \"files\": [\"/path/to/your/video_file.mp4\"],\n",
    "        \"audio_format\": \"wav\",\n",
    "        \"audio_codec\": \"pcm_s16le\",\n",
    "        \"output_folder\": \"/path/to/output/audios\"\n",
    "    },\n",
    "    \"service\": {\n",
    "        \"service_name\": \"ffmpeg\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# Output the response from the video IO task\n",
    "print(\"Video IO Task Response:\", video_io_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio IO Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio IO Task\n",
    "# -------------\n",
    "# This section shows how to read audio files from disk using AudioIOTask.\n",
    "\n",
    "# Creating an instance of AudioIOTask\n",
    "audio_io_task = AudioIOTask()\n",
    "\n",
    "# Reading audios from disk\n",
    "audio_io_response = audio_io_task.read_audios_from_disk({\n",
    "    \"data\": {\n",
    "        \"files\": [\n",
    "            \"/path/to/audio/file1.wav\",\n",
    "            \"/path/to/audio/file2.wav\",\n",
    "            \"/path/to/audio/file3.wav\"\n",
    "        ]\n",
    "    },\n",
    "    \"service\": {\n",
    "        \"service_name\": \"Datasets\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# Accessing the output from the response which is a list of audio data\n",
    "audio_dataset = audio_io_response['output']\n",
    "\n",
    "# Displaying information about the first and last audio files in the dataset\n",
    "print(\"First audio shape:\", audio_dataset[0]['audio']['array'].shape)\n",
    "print(\"First audio array:\", audio_dataset[0]['audio']['array'])\n",
    "print(\"Last audio shape:\", audio_dataset[-1]['audio']['array'].shape)\n",
    "print(\"Last audio array:\", audio_dataset[-1]['audio']['array'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Signal Processing Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Not working #\n",
    "# Raw Signal Processing Task\n",
    "# --------------------------\n",
    "# This section demonstrates the use of RawSignalProcessingTask to perform operations like channel selection and resampling.\n",
    "\n",
    "from pipepal.audio.tasks import RawSignalProcessingTask\n",
    "\n",
    "# Instantiate your class\n",
    "raw_signal_processing_task = RawSignalProcessingTask()\n",
    "\n",
    "# Running the raw signal processing task with the previously created audio dataset\n",
    "asp_response = raw_signal_processing_task.run({\n",
    "    \"data\": {\n",
    "        \"dataset\": audio_dataset,\n",
    "        \"channeling\": {\n",
    "            \"method\": \"selection\",  # alternative is \"average\"\n",
    "            \"channels_to_keep\": [0]\n",
    "        },\n",
    "        \"resampling\": {\n",
    "            \"rate\": 16000,\n",
    "        }\n",
    "    },\n",
    "    \"service\": {\n",
    "        \"service_name\": \"torchaudio\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# Accessing the new audio dataset from the response\n",
    "new_audio_dataset = asp_response['output']\n",
    "\n",
    "# Printing details about the processed audio dataset\n",
    "print(\"Processed audio dataset:\", new_audio_dataset)\n",
    "print(\"Shape of last audio array in processed dataset:\", new_audio_dataset[-1]['audio']['array'].shape)\n",
    "print(\"Last audio array in processed dataset:\", new_audio_dataset[-1]['audio']['array'])\n",
    "\n",
    "# Optionally, pushing the new audio dataset to a hub\n",
    "# Uncomment the following line to perform this action\n",
    "# new_audio_dataset.push_to_hub(\"your_hub_repository_name\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipepal-dH98wMGu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
